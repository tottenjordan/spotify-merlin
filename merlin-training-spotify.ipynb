{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab61e54-c285-419d-84cd-07c21d0d1b4f",
   "metadata": {},
   "source": [
    "# Train Merlin TwoTower model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d397e1-93ee-4add-a99e-c137f186c1df",
   "metadata": {},
   "source": [
    "### Notebook Steps\n",
    "* Build custom Vertex training container based on NVIDIA NGC Merlin Training container\n",
    "* Confiruger and submit Vertec custom training job\n",
    "* Configure and submit hyperparameter tuning job\n",
    "* Evaluate results of hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fa93d-d0d6-4043-b0f7-87fa51b294c0",
   "metadata": {},
   "source": [
    "### Negative Sampling\n",
    "\n",
    "* Merlin provides scalable negative sampling algorithms for the Item Retrieval Task \n",
    "* In this example, the in-batch sampling algorithm, which uses the items interacted by other users as negatives within the same mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee605fb-69f0-471d-b4fd-e709a89f1704",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ab64fe-6122-4434-9d15-7e1531166cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1a9e1a-d762-4b87-884e-3989018674e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Project definitions\n",
    "PROJECT_ID = 'hybrid-vertex' # Change to your project ID.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "\n",
    "# TODO: Service Account address\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com' # Change to your service account with Vertex AI Admin permitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4095983-7e05-41f4-be58-dc0edf7887f0",
   "metadata": {},
   "source": [
    "### For HugeCTR data access\n",
    "\n",
    "* must be a `/gcs/BUCKET_NAME/...` path for GCSFuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdadc296-bb21-48a1-92a8-6522fe01b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GCSFuse file lists\n",
    "TRAIN_DATA = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v10-subset/nvt-processed/train/_gcs_file_list.txt'\n",
    "VALID_DATA = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v10-subset/nvt-processed/valid/_gcs_file_list.txt'\n",
    "\n",
    "# Schema used by the training pipepine\n",
    "SCHEMA_PATH = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v10-subset/nvt-processed/train/schema.pbtxt'\n",
    "\n",
    "# Merline Datatsets\n",
    "# train = MerlinDataset(output_train_dir + \"/*.parquet\", schema=schema, part_size=\"500MB\")\n",
    "# valid = MerlinDataset(output_valid_dir + \"/*.parquet\", schema=schema, part_size=\"500MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc25ea-9a8b-4529-9bac-d9b9e94197ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket definitions\n",
    "BUCKET = 'spotify-merlin-v1'\n",
    "\n",
    "VERSION = 'v01-subset'\n",
    "MODEL_NAME = 'TwoTower'\n",
    "MODEL_DISPLAY_NAME = f'hugectr-{MODEL_NAME}-{VERSION}'\n",
    "WORKSPACE = f'gs://{BUCKET}/{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "# Docker definitions for training\n",
    "IMAGE_NAME = f'hugectr-{MODEL_NAME}-training-{VERSION}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "DOCKERNAME = 'hugectr'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab977659-5bc6-4870-a71c-67d2c2b0cf48",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d464da-e45f-47ed-a440-74ab9af100c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=os.path.join(WORKSPACE, 'stg')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918f31f-1e7f-4ea1-b50f-12f026bf02e9",
   "metadata": {},
   "source": [
    "### Submit a Vertex custom training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49211568-62a4-4699-830d-26a70b294f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
