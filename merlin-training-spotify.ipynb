{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ab61e54-c285-419d-84cd-07c21d0d1b4f",
   "metadata": {},
   "source": [
    "# Train Merlin TwoTower model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d397e1-93ee-4add-a99e-c137f186c1df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Notebook Steps\n",
    "* Build custom Vertex training container based on NVIDIA NGC Merlin Training container\n",
    "* Confiruger and submit Vertec custom training job\n",
    "* Configure and submit hyperparameter tuning job\n",
    "* Evaluate results of hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fa93d-d0d6-4043-b0f7-87fa51b294c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Negative Sampling\n",
    "\n",
    "* Merlin provides scalable negative sampling algorithms for the Item Retrieval Task \n",
    "* In this example, the in-batch sampling algorithm, which uses the items interacted by other users as negatives within the same mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73568d60-38d3-432c-939c-98bb6917065f",
   "metadata": {},
   "source": [
    "## Training Strategy\n",
    "\n",
    "* `MirroredStrategy`: Train on a single VM with multiple GPUs.\n",
    "* `MultiWorkerMirroredStrategy`: Train on multiple VMs with automatic setup of replicas.\n",
    "* `MultiWorkerMirroredStrategy`: Train on multiple VMs with fine grain control of replicas.\n",
    "* `ReductionServer`: Train on multiple VMS and sync updates across VMS with Vertex AI Reduction Server.\n",
    "* `TPUTraining`: Train with multiple Cloud TPUs.\n",
    "\n",
    "### Mirrored Strategy\n",
    "When training on a single VM, one can either train was a single compute device or with multiple compute devices on the same VM. With Vertex AI Distributed Training you can specify both the number of compute devices for the VM instance and type of compute devices: CPU, GPU.\n",
    "\n",
    "Vertex AI Distributed Training supports `tf.distribute.MirroredStrategy' for TensorFlow models. \n",
    "\n",
    "To enable training across multiple compute devices on the same VM, you do the following additional steps in your Python training script:\n",
    "\n",
    "1. Set the tf.distribute.MirrorStrategy\n",
    "2. Compile the model within the scope of tf.distribute.MirrorStrategy. Note: Tells MirroredStrategy which variables to mirror across your compute devices.\n",
    "3. Increase the batch size for each compute device to num_devices * batch size.\n",
    "\n",
    "During transitions, the distribution of batches will be synchronized as well as the updates to the model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee605fb-69f0-471d-b4fd-e709a89f1704",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "c5ab64fe-6122-4434-9d15-7e1531166cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "ba1a9e1a-d762-4b87-884e-3989018674e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Project definitions\n",
    "PROJECT_ID = 'hybrid-vertex' # Change to your project ID.\n",
    "REGION = 'us-central1' # Change to your region.\n",
    "\n",
    "# TODO: Service Account address\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com' # Change to your service account with Vertex AI Admin permitions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4095983-7e05-41f4-be58-dc0edf7887f0",
   "metadata": {},
   "source": [
    "### For HugeCTR data access\n",
    "\n",
    "* must be a `/gcs/BUCKET_NAME/...` path for GCSFuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "cdadc296-bb21-48a1-92a8-6522fe01b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GCSFuse file lists\n",
    "# TRAIN_DATA = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-processed/train/_gcs_file_list.txt'\n",
    "# VALID_DATA = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-processed/valid/_gcs_file_list.txt'\n",
    "\n",
    "# Schema used by the training pipepine\n",
    "# SCHEMA_PATH = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v25-subset/nvt-defined/train/schema.pbtxt'\n",
    "\n",
    "# Merline Datatsets\n",
    "# train = MerlinDataset(output_train_dir + \"/*.parquet\", schema=schema, part_size=\"500MB\")\n",
    "# valid = MerlinDataset(output_valid_dir + \"/*.parquet\", schema=schema, part_size=\"500MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4dfc25ea-9a8b-4529-9bac-d9b9e94197ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket definitions\n",
    "BUCKET = 'spotify-merlin-v1'\n",
    "\n",
    "VERSION = 'v13' # changed merlin image from \"..:07\" to \"...:06\"\n",
    "MODEL_NAME = 'twotower'\n",
    "FRAMEWORK = 'merlin-tf'\n",
    "MODEL_DISPLAY_NAME = f'vertex-{FRAMEWORK}-{MODEL_NAME}-{VERSION}'\n",
    "WORKSPACE = f'gs://{BUCKET}/{MODEL_DISPLAY_NAME}'\n",
    "\n",
    "# Docker definitions for training\n",
    "IMAGE_NAME = f'{FRAMEWORK}-{MODEL_NAME}-training-{VERSION}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "# DOCKERNAME = 'hugectr'\n",
    "DOCKERNAME = 'merlintf'\n",
    "MACHINE_TYPE ='e2-highcpu-32'\n",
    "FILE_LOCATION = './src'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab977659-5bc6-4870-a71c-67d2c2b0cf48",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "03d464da-e45f-47ed-a440-74ab9af100c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION,\n",
    "    staging_bucket=os.path.join(WORKSPACE, 'staging')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffb16c3-4592-469a-a88a-e6e915c10102",
   "metadata": {},
   "source": [
    "### Create Train Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2395e840-1d45-4b1c-800c-2472e6164b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/spotify-merlin\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "6d7e14d9-fbd3-47c4-b8df-e94e005b2221",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0b300-d6d8-4933-9807-1e540dfa697e",
   "metadata": {},
   "source": [
    "> `RUN pip install merlin-models==0.6.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2d47c0cc-9a3a-4f09-bfdb-f971188fea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/Dockerfile.merlintf\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{DOCKERNAME}\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.07\n",
    "\n",
    "WORKDIR /src\n",
    "\n",
    "RUN pip install -U pip\n",
    "RUN pip install google-cloud-bigquery gcsfs cloudml-hypertune\n",
    "RUN pip install google-cloud-aiplatform kfp\n",
    "RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && apt-get update -y && apt-get install google-cloud-sdk -y\n",
    "\n",
    "COPY training/* ./\n",
    "\n",
    "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/compat/lib.real:/usr/local/hugectr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "37c24626-ccf8-4df2-9aa0-4dbcb5169ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCKERNAME: merlintf\n",
      "IMAGE_URI: gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13\n",
      "FILE_LOCATION: ./src\n",
      "MACHINE_TYPE: e2-highcpu-32\n"
     ]
    }
   ],
   "source": [
    "print(f\"DOCKERNAME: {DOCKERNAME}\")\n",
    "print(f\"IMAGE_URI: {IMAGE_URI}\")\n",
    "print(f\"FILE_LOCATION: {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE: {MACHINE_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918f31f-1e7f-4ea1-b50f-12f026bf02e9",
   "metadata": {},
   "source": [
    "### Submit a Vertex custom training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a82c46aa-c63a-4184-a727-27d686171050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/jupyter/spotify-merlin/src/training\u001b[00m\n",
      "├── __init__.py\n",
      "├── train_task.py\n",
      "├── training.py\n",
      "├── two_tower_model.py\n",
      "└── utils.py\n",
      "\n",
      "0 directories, 5 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/jupyter/spotify-merlin/src/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8abc1415-7841-47b3-a699-8bc44e36ccb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/spotify-merlin'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/jupyter/spotify-merlin')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "49211568-62a4-4699-830d-26a70b294f66",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 81 file(s) totalling 1.7 MiB before compression.\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1663106031.143978-8a29bbba89d949f1a8d2ec5cb8c03e4e.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/global/builds/fab486f3-ccbc-4666-8ef0-fcc0454f1dde].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/fab486f3-ccbc-4666-8ef0-fcc0454f1dde?project=934903580331].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"fab486f3-ccbc-4666-8ef0-fcc0454f1dde\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1663106031.143978-8a29bbba89d949f1a8d2ec5cb8c03e4e.tgz#1663106031670083\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1663106031.143978-8a29bbba89d949f1a8d2ec5cb8c03e4e.tgz#1663106031670083...\n",
      "/ [1 files][215.7 KiB/215.7 KiB]                                                \n",
      "Operation completed over 1 objects/215.7 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon   1.06MB\n",
      "Step 1/8 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.07\n",
      "22.07: Pulling from nvidia/merlin/merlin-tensorflow\n",
      "d7bfe07ed847: Pulling fs layer\n",
      "4256836e525f: Pulling fs layer\n",
      "19f0d80655c9: Pulling fs layer\n",
      "58206f9095ad: Pulling fs layer\n",
      "d2a30fa05b26: Pulling fs layer\n",
      "fc77cb5b926d: Pulling fs layer\n",
      "ef352a62ee1a: Pulling fs layer\n",
      "a3bd3aeb5eff: Pulling fs layer\n",
      "1e4275fc348a: Pulling fs layer\n",
      "c4ee4e3a08c4: Pulling fs layer\n",
      "cec49411216f: Pulling fs layer\n",
      "ba316fa62517: Pulling fs layer\n",
      "96c199ab7e47: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "89163c7c351c: Pulling fs layer\n",
      "a1a638179bf5: Pulling fs layer\n",
      "0aae5e8cd6b2: Pulling fs layer\n",
      "d362ce85c502: Pulling fs layer\n",
      "c0f12e55b7c4: Pulling fs layer\n",
      "6f373b11cef6: Pulling fs layer\n",
      "b680ff47b230: Pulling fs layer\n",
      "5997f3c8600e: Pulling fs layer\n",
      "60105f748676: Pulling fs layer\n",
      "312ea873c9fa: Pulling fs layer\n",
      "991ea607ec34: Pulling fs layer\n",
      "832ff5dc6a40: Pulling fs layer\n",
      "f58b46ff2880: Pulling fs layer\n",
      "c8954fb7a586: Pulling fs layer\n",
      "c0223c81c9ce: Pulling fs layer\n",
      "3365bb70925f: Pulling fs layer\n",
      "aa3202551ca0: Pulling fs layer\n",
      "f7feb4f10cb9: Pulling fs layer\n",
      "9c720d305d72: Pulling fs layer\n",
      "817c56e44706: Pulling fs layer\n",
      "f4fcb3e06f36: Pulling fs layer\n",
      "bf2a0f9b976a: Pulling fs layer\n",
      "ac3e7470b6f5: Pulling fs layer\n",
      "cb04679b7928: Pulling fs layer\n",
      "c08b8122befe: Pulling fs layer\n",
      "c12c983ba6ae: Pulling fs layer\n",
      "261d57f99470: Pulling fs layer\n",
      "3106a8c92c64: Pulling fs layer\n",
      "62c82a7cc3f8: Pulling fs layer\n",
      "d850c2aeb28e: Pulling fs layer\n",
      "0cdb75c86984: Pulling fs layer\n",
      "f1f8ac7380bd: Pulling fs layer\n",
      "bfeac2d21d46: Pulling fs layer\n",
      "964776b850f4: Pulling fs layer\n",
      "1ec2ff9dce2f: Pulling fs layer\n",
      "82f580ec703f: Pulling fs layer\n",
      "e3964e79c4f0: Pulling fs layer\n",
      "5526ea20cb3c: Pulling fs layer\n",
      "154512fcf9b9: Pulling fs layer\n",
      "89163c7c351c: Waiting\n",
      "99c11153494b: Pulling fs layer\n",
      "a1a638179bf5: Waiting\n",
      "94e298e39429: Pulling fs layer\n",
      "8f15a7d7af73: Pulling fs layer\n",
      "0aae5e8cd6b2: Waiting\n",
      "d362ce85c502: Waiting\n",
      "c0f12e55b7c4: Waiting\n",
      "6f373b11cef6: Waiting\n",
      "312ea873c9fa: Waiting\n",
      "b680ff47b230: Waiting\n",
      "991ea607ec34: Waiting\n",
      "5997f3c8600e: Waiting\n",
      "60105f748676: Waiting\n",
      "832ff5dc6a40: Waiting\n",
      "f58b46ff2880: Waiting\n",
      "c8954fb7a586: Waiting\n",
      "c0223c81c9ce: Waiting\n",
      "3365bb70925f: Waiting\n",
      "aa3202551ca0: Waiting\n",
      "f7feb4f10cb9: Waiting\n",
      "9c720d305d72: Waiting\n",
      "817c56e44706: Waiting\n",
      "f4fcb3e06f36: Waiting\n",
      "bf2a0f9b976a: Waiting\n",
      "99c11153494b: Waiting\n",
      "ac3e7470b6f5: Waiting\n",
      "e3964e79c4f0: Waiting\n",
      "82f580ec703f: Waiting\n",
      "94e298e39429: Waiting\n",
      "cb04679b7928: Waiting\n",
      "bfeac2d21d46: Waiting\n",
      "c08b8122befe: Waiting\n",
      "5526ea20cb3c: Waiting\n",
      "8f15a7d7af73: Waiting\n",
      "154512fcf9b9: Waiting\n",
      "c12c983ba6ae: Waiting\n",
      "964776b850f4: Waiting\n",
      "58206f9095ad: Waiting\n",
      "0cdb75c86984: Waiting\n",
      "261d57f99470: Waiting\n",
      "d2a30fa05b26: Waiting\n",
      "c4ee4e3a08c4: Waiting\n",
      "1ec2ff9dce2f: Waiting\n",
      "f1f8ac7380bd: Waiting\n",
      "fc77cb5b926d: Waiting\n",
      "3106a8c92c64: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "ef352a62ee1a: Waiting\n",
      "96c199ab7e47: Waiting\n",
      "62c82a7cc3f8: Waiting\n",
      "cec49411216f: Waiting\n",
      "ba316fa62517: Waiting\n",
      "a3bd3aeb5eff: Waiting\n",
      "d850c2aeb28e: Waiting\n",
      "1e4275fc348a: Waiting\n",
      "d7bfe07ed847: Verifying Checksum\n",
      "d7bfe07ed847: Download complete\n",
      "4256836e525f: Verifying Checksum\n",
      "4256836e525f: Download complete\n",
      "58206f9095ad: Download complete\n",
      "19f0d80655c9: Download complete\n",
      "fc77cb5b926d: Verifying Checksum\n",
      "fc77cb5b926d: Download complete\n",
      "ef352a62ee1a: Verifying Checksum\n",
      "ef352a62ee1a: Download complete\n",
      "d7bfe07ed847: Pull complete\n",
      "a3bd3aeb5eff: Verifying Checksum\n",
      "a3bd3aeb5eff: Download complete\n",
      "1e4275fc348a: Verifying Checksum\n",
      "1e4275fc348a: Download complete\n",
      "c4ee4e3a08c4: Verifying Checksum\n",
      "c4ee4e3a08c4: Download complete\n",
      "ba316fa62517: Verifying Checksum\n",
      "ba316fa62517: Download complete\n",
      "cec49411216f: Verifying Checksum\n",
      "cec49411216f: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "89163c7c351c: Verifying Checksum\n",
      "89163c7c351c: Download complete\n",
      "a1a638179bf5: Verifying Checksum\n",
      "a1a638179bf5: Download complete\n",
      "4256836e525f: Pull complete\n",
      "0aae5e8cd6b2: Verifying Checksum\n",
      "0aae5e8cd6b2: Download complete\n",
      "96c199ab7e47: Verifying Checksum\n",
      "96c199ab7e47: Download complete\n",
      "c0f12e55b7c4: Verifying Checksum\n",
      "c0f12e55b7c4: Download complete\n",
      "6f373b11cef6: Verifying Checksum\n",
      "6f373b11cef6: Download complete\n",
      "19f0d80655c9: Pull complete\n",
      "58206f9095ad: Pull complete\n",
      "b680ff47b230: Verifying Checksum\n",
      "b680ff47b230: Download complete\n",
      "5997f3c8600e: Download complete\n",
      "d362ce85c502: Verifying Checksum\n",
      "d362ce85c502: Download complete\n",
      "312ea873c9fa: Verifying Checksum\n",
      "312ea873c9fa: Download complete\n",
      "991ea607ec34: Verifying Checksum\n",
      "991ea607ec34: Download complete\n",
      "832ff5dc6a40: Verifying Checksum\n",
      "832ff5dc6a40: Download complete\n",
      "f58b46ff2880: Verifying Checksum\n",
      "f58b46ff2880: Download complete\n",
      "c8954fb7a586: Verifying Checksum\n",
      "c8954fb7a586: Download complete\n",
      "60105f748676: Verifying Checksum\n",
      "60105f748676: Download complete\n",
      "c0223c81c9ce: Download complete\n",
      "3365bb70925f: Verifying Checksum\n",
      "3365bb70925f: Download complete\n",
      "aa3202551ca0: Verifying Checksum\n",
      "aa3202551ca0: Download complete\n",
      "f7feb4f10cb9: Verifying Checksum\n",
      "f7feb4f10cb9: Download complete\n",
      "9c720d305d72: Verifying Checksum\n",
      "9c720d305d72: Download complete\n",
      "f4fcb3e06f36: Verifying Checksum\n",
      "f4fcb3e06f36: Download complete\n",
      "817c56e44706: Verifying Checksum\n",
      "817c56e44706: Download complete\n",
      "bf2a0f9b976a: Download complete\n",
      "cb04679b7928: Verifying Checksum\n",
      "cb04679b7928: Download complete\n",
      "c08b8122befe: Verifying Checksum\n",
      "c08b8122befe: Download complete\n",
      "d2a30fa05b26: Verifying Checksum\n",
      "d2a30fa05b26: Download complete\n",
      "c12c983ba6ae: Verifying Checksum\n",
      "c12c983ba6ae: Download complete\n",
      "ac3e7470b6f5: Verifying Checksum\n",
      "ac3e7470b6f5: Download complete\n",
      "3106a8c92c64: Verifying Checksum\n",
      "3106a8c92c64: Download complete\n",
      "261d57f99470: Verifying Checksum\n",
      "261d57f99470: Download complete\n",
      "62c82a7cc3f8: Verifying Checksum\n",
      "62c82a7cc3f8: Download complete\n",
      "d850c2aeb28e: Verifying Checksum\n",
      "d850c2aeb28e: Download complete\n",
      "0cdb75c86984: Verifying Checksum\n",
      "0cdb75c86984: Download complete\n",
      "964776b850f4: Download complete\n",
      "1ec2ff9dce2f: Verifying Checksum\n",
      "1ec2ff9dce2f: Download complete\n",
      "82f580ec703f: Verifying Checksum\n",
      "82f580ec703f: Download complete\n",
      "e3964e79c4f0: Verifying Checksum\n",
      "e3964e79c4f0: Download complete\n",
      "f1f8ac7380bd: Verifying Checksum\n",
      "f1f8ac7380bd: Download complete\n",
      "154512fcf9b9: Verifying Checksum\n",
      "154512fcf9b9: Download complete\n",
      "99c11153494b: Verifying Checksum\n",
      "99c11153494b: Download complete\n",
      "bfeac2d21d46: Verifying Checksum\n",
      "bfeac2d21d46: Download complete\n",
      "5526ea20cb3c: Verifying Checksum\n",
      "5526ea20cb3c: Download complete\n",
      "8f15a7d7af73: Verifying Checksum\n",
      "8f15a7d7af73: Download complete\n",
      "94e298e39429: Verifying Checksum\n",
      "94e298e39429: Download complete\n",
      "d2a30fa05b26: Pull complete\n",
      "fc77cb5b926d: Pull complete\n",
      "ef352a62ee1a: Pull complete\n",
      "a3bd3aeb5eff: Pull complete\n",
      "1e4275fc348a: Pull complete\n",
      "c4ee4e3a08c4: Pull complete\n",
      "cec49411216f: Pull complete\n",
      "ba316fa62517: Pull complete\n",
      "96c199ab7e47: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "89163c7c351c: Pull complete\n",
      "a1a638179bf5: Pull complete\n",
      "0aae5e8cd6b2: Pull complete\n",
      "d362ce85c502: Pull complete\n",
      "c0f12e55b7c4: Pull complete\n",
      "6f373b11cef6: Pull complete\n",
      "b680ff47b230: Pull complete\n",
      "5997f3c8600e: Pull complete\n",
      "60105f748676: Pull complete\n",
      "312ea873c9fa: Pull complete\n",
      "991ea607ec34: Pull complete\n",
      "832ff5dc6a40: Pull complete\n",
      "f58b46ff2880: Pull complete\n",
      "c8954fb7a586: Pull complete\n",
      "c0223c81c9ce: Pull complete\n",
      "3365bb70925f: Pull complete\n",
      "aa3202551ca0: Pull complete\n",
      "f7feb4f10cb9: Pull complete\n",
      "9c720d305d72: Pull complete\n",
      "817c56e44706: Pull complete\n",
      "f4fcb3e06f36: Pull complete\n",
      "bf2a0f9b976a: Pull complete\n",
      "ac3e7470b6f5: Pull complete\n",
      "cb04679b7928: Pull complete\n",
      "c08b8122befe: Pull complete\n",
      "c12c983ba6ae: Pull complete\n",
      "261d57f99470: Pull complete\n",
      "3106a8c92c64: Pull complete\n",
      "62c82a7cc3f8: Pull complete\n",
      "d850c2aeb28e: Pull complete\n",
      "0cdb75c86984: Pull complete\n",
      "f1f8ac7380bd: Pull complete\n",
      "bfeac2d21d46: Pull complete\n",
      "964776b850f4: Pull complete\n",
      "1ec2ff9dce2f: Pull complete\n",
      "82f580ec703f: Pull complete\n",
      "e3964e79c4f0: Pull complete\n",
      "5526ea20cb3c: Pull complete\n",
      "154512fcf9b9: Pull complete\n",
      "99c11153494b: Pull complete\n",
      "94e298e39429: Pull complete\n",
      "8f15a7d7af73: Pull complete\n",
      "Digest: sha256:2ef75a39ef92749dd2b79e002c2910818bdcdd01596198650243c483a7124167\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/merlin/merlin-tensorflow:22.07\n",
      " ---> b5324e8a331b\n",
      "Step 2/8 : WORKDIR /src\n",
      " ---> Running in 801084c08aff\n",
      "Removing intermediate container 801084c08aff\n",
      " ---> 73b60c1f0472\n",
      "Step 3/8 : RUN pip install -U pip\n",
      " ---> Running in b313b4e10606\n",
      "Collecting pip\n",
      "  Downloading pip-22.2.2-py3-none-any.whl (2.0 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.0.2\n",
      "    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\n",
      "    Can't uninstall 'pip'. No files were found to uninstall.\n",
      "Successfully installed pip-22.2.2\n",
      "Removing intermediate container b313b4e10606\n",
      " ---> cde57846af92\n",
      "Step 4/8 : RUN pip install google-cloud-bigquery gcsfs cloudml-hypertune\n",
      " ---> Running in 0f358a55c880\n",
      "Collecting google-cloud-bigquery\n",
      "  Downloading google_cloud_bigquery-3.3.2-py2.py3-none-any.whl (211 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.9/211.9 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2022.8.2-py2.py3-none-any.whl (25 kB)\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-cloud-bigquery-storage<3.0.0dev,>=2.0.0\n",
      "  Downloading google_cloud_bigquery_storage-2.15.0-py2.py3-none-any.whl (182 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 182.8/182.8 kB 29.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery) (21.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/lib/python3/dist-packages (from google-cloud-bigquery) (2.22.0)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.19.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery) (3.19.4)\n",
      "Collecting grpcio<2.0dev,>=1.47.0\n",
      "  Downloading grpcio-1.48.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 68.0 MB/s eta 0:00:00\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.9/47.9 kB 8.7 MB/s eta 0:00:00\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.10.0-py3-none-any.whl (115 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.3/115.3 kB 20.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyarrow<10.0dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery) (6.0.0)\n",
      "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
      "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.9/76.9 kB 14.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs) (5.1.1)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 73.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs) (2.9.1)\n",
      "Collecting fsspec==2022.8.2\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.8/140.8 kB 28.0 MB/s eta 0:00:00\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.5.0-py2.py3-none-any.whl (106 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 107.0/107.0 kB 20.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.8/dist-packages (from gcsfs) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 262.1/262.1 kB 19.4 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (6.0.2)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 28.0 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting protobuf<5.0.0dev,>=3.19.0\n",
      "  Downloading protobuf-4.21.5-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 408.4/408.4 kB 44.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.56.4)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2\n",
      "  Downloading grpcio_status-1.48.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs) (5.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs) (1.14.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-bigquery) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from pyarrow<10.0dev,>=3.0.0->google-cloud-bigquery) (1.21.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs) (2.8)\n",
      "Building wheels for collected packages: cloudml-hypertune\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3986 sha256=d1aa43fe6fc4728e7b636a803290c78fd8e51d934c2aaf04794e0cfbcc602acf\n",
      "  Stored in directory: /root/.cache/pip/wheels/87/fb/3b/365271726c73d8bc0b5bf39ef0f5db5a9c75b2babe4fd67794\n",
      "Successfully built cloudml-hypertune\n",
      "Installing collected packages: cloudml-hypertune, yarl, protobuf, grpcio, google-crc32c, fsspec, frozenlist, charset-normalizer, async-timeout, proto-plus, google-resumable-media, aiosignal, grpcio-status, google-api-core, aiohttp, google-cloud-core, google-cloud-storage, google-cloud-bigquery-storage, google-cloud-bigquery, gcsfs\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.4\n",
      "    Uninstalling protobuf-3.19.4:\n",
      "      Successfully uninstalled protobuf-3.19.4\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.41.0\n",
      "    Uninstalling grpcio-1.41.0:\n",
      "      Successfully uninstalled grpcio-1.41.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.0\n",
      "    Uninstalling fsspec-2022.7.0:\n",
      "      Successfully uninstalled fsspec-2022.7.0\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 22.4.0 requires cupy-cuda117, which is not installed.\n",
      "cudf 22.4.0 requires cupy-cuda117, which is not installed.\n",
      "wandb 0.12.21 requires protobuf<4.0dev,>=3.12.0, but you have protobuf 4.21.5 which is incompatible.\n",
      "tensorflow-metadata 1.9.0 requires protobuf<4,>=3.13, but you have protobuf 4.21.5 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible.\n",
      "dask-cuda 22.4.0 requires click==8.0.4, but you have click 8.1.3 which is incompatible.\n",
      "\u001b[0mSuccessfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 charset-normalizer-2.1.1 cloudml-hypertune-0.1.0.dev6 frozenlist-1.3.1 fsspec-2022.8.2 gcsfs-2022.8.2 google-api-core-2.10.0 google-cloud-bigquery-3.3.2 google-cloud-bigquery-storage-2.15.0 google-cloud-core-2.3.2 google-cloud-storage-2.5.0 google-crc32c-1.5.0 google-resumable-media-2.3.3 grpcio-1.48.1 grpcio-status-1.48.1 proto-plus-1.22.1 protobuf-4.21.5 yarl-1.8.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 0f358a55c880\n",
      " ---> c24d2d87a1d7\n",
      "Step 5/8 : RUN pip install google-cloud-aiplatform kfp\n",
      " ---> Running in 2a3b812da6a8\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.17.0-py2.py3-none-any.whl (2.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 29.3 MB/s eta 0:00:00\n",
      "Collecting kfp\n",
      "  Downloading kfp-1.8.13.tar.gz (300 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.1/300.1 kB 39.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform) (2.10.0)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.6.1-py2.py3-none-any.whl (231 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 231.1/231.1 kB 33.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform) (1.22.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform) (21.3)\n",
      "Requirement already satisfied: protobuf<5.0.0dev,>=3.19.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform) (4.21.5)\n",
      "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-2.34.4-py2.py3-none-any.whl (206 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.6/206.6 kB 30.5 MB/s eta 0:00:00\n",
      "Collecting Deprecated<2,>=1.2.7\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting PyYAML<6,>=5.3\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 662.4/662.4 kB 49.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.8/dist-packages (from kfp) (1.2.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from kfp) (8.1.3)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from kfp) (2.1.0)\n",
      "Collecting docstring-parser<1,>=0.7.3\n",
      "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
      "Collecting fire<1,>=0.3.1\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 kB 15.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-api-python-client<2,>=1.7.8\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.1/62.1 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting google-auth<2,>=1.6.1\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.9/152.9 kB 25.1 MB/s eta 0:00:00\n",
      "Collecting google-cloud-storage<3.0.0dev,>=1.32.0\n",
      "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.8/106.8 kB 15.5 MB/s eta 0:00:00\n",
      "Collecting jsonschema<4,>=3.0.1\n",
      "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 kB 8.3 MB/s eta 0:00:00\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.14\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.1/58.1 kB 9.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting kubernetes<19,>=8.0.0\n",
      "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 77.0 MB/s eta 0:00:00\n",
      "Collecting protobuf<5.0.0dev,>=3.19.0\n",
      "  Downloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 162.1/162.1 kB 25.8 MB/s eta 0:00:00\n",
      "Collecting pydantic<2,>=1.8.2\n",
      "  Downloading pydantic-1.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.6/13.6 MB 88.3 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<1,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.3/54.3 kB 8.9 MB/s eta 0:00:00\n",
      "Collecting strip-hints<1,>=0.1.8\n",
      "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tabulate<1,>=0.8.6\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting typer<1.0,>=0.3.2\n",
      "  Downloading typer-0.6.1-py3-none-any.whl (38 kB)\n",
      "Collecting uritemplate<4,>=3.0.1\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from kfp) (4.3.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from Deprecated<2,>=1.2.7->kfp) (1.14.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from fire<1,>=0.3.1->kfp) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/lib/python3/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.22.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.56.4)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.1)\n",
      "Collecting google-auth-httplib2>=0.0.3\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 16.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/lib/python3/dist-packages (from google-auth<2,>=1.6.1->kfp) (45.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.1->kfp) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<2,>=1.6.1->kfp) (0.2.8)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2019.11.28)\n",
      "Requirement already satisfied: urllib3>=1.15 in /usr/lib/python3/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.25.8)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.8/dist-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.3)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.8/dist-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform) (3.0.9)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from strip-hints<1,>=0.1.8->kfp) (0.34.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Building wheels for collected packages: kfp, fire, kfp-server-api, strip-hints\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.8.13-py3-none-any.whl size=422437 sha256=04fc31a6b502206fa7f08ed49606245494f33106bc7440cbf44bf22d386d5489\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/43/81/54fab9af9e713ad72750589ab82a44426e03bb8741020d8a92\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115925 sha256=9f5ad371c1385a8d3959474427a48abfda9a5242e6e998be7db53909a2ef033f\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99699 sha256=d8c0d1646373672a04a92b033371f1b83e365a5884420426b8f331e91601abe6\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/b7/87/8884b574029455610a5b99752115d2ac857f8cfe8b846a1225\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22279 sha256=2e021ba48c1032a8c655dcdb7c249455a7f2bde6fa640638ba81771a3f3c0755\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/16/9b/7c21f4d08b98d02819658600b738d3453b2ffee3c9b757629e\n",
      "Successfully built kfp fire kfp-server-api strip-hints\n",
      "Installing collected packages: uritemplate, typer, tabulate, strip-hints, requests-toolbelt, PyYAML, pydantic, protobuf, jsonschema, httplib2, fire, docstring-parser, Deprecated, cachetools, kfp-server-api, kfp-pipeline-spec, google-auth, kubernetes, google-auth-httplib2, grpc-google-iam-v1, google-api-python-client, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, kfp, google-cloud-aiplatform\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.5\n",
      "    Uninstalling protobuf-4.21.5:\n",
      "      Successfully uninstalled protobuf-4.21.5\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.8.0\n",
      "    Uninstalling jsonschema-4.8.0:\n",
      "      Successfully uninstalled jsonschema-4.8.0\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 5.2.0\n",
      "    Uninstalling cachetools-5.2.0:\n",
      "      Successfully uninstalled cachetools-5.2.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.9.1\n",
      "    Uninstalling google-auth-2.9.1:\n",
      "      Successfully uninstalled google-auth-2.9.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.5.0\n",
      "    Uninstalling google-cloud-storage-2.5.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.5.0\n",
      "  Attempting uninstall: google-cloud-bigquery\n",
      "    Found existing installation: google-cloud-bigquery 3.3.2\n",
      "    Uninstalling google-cloud-bigquery-3.3.2:\n",
      "      Successfully uninstalled google-cloud-bigquery-3.3.2\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dask-cudf 22.4.0 requires cupy-cuda117, which is not installed.\n",
      "cudf 22.4.0 requires cupy-cuda117, which is not installed.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.2 which is incompatible.\n",
      "dask-cuda 22.4.0 requires click==8.0.4, but you have click 8.1.3 which is incompatible.\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.13 PyYAML-5.4.1 cachetools-4.2.4 docstring-parser-0.15 fire-0.4.0 google-api-python-client-1.12.11 google-auth-1.35.0 google-auth-httplib2-0.1.0 google-cloud-aiplatform-1.17.0 google-cloud-bigquery-2.34.4 google-cloud-resource-manager-1.6.1 google-cloud-storage-1.44.0 grpc-google-iam-v1-0.12.4 httplib2-0.20.4 jsonschema-3.2.0 kfp-1.8.13 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-18.20.0 protobuf-3.20.2 pydantic-1.10.2 requests-toolbelt-0.9.1 strip-hints-0.1.10 tabulate-0.8.10 typer-0.6.1 uritemplate-3.0.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 2a3b812da6a8\n",
      " ---> 8e2a2f6bd895\n",
      "Step 6/8 : RUN echo \"deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key --keyring /usr/share/keyrings/cloud.google.gpg  add - && apt-get update -y && apt-get install google-cloud-sdk -y\n",
      " ---> Running in 522646b711ca\n",
      "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] http://packages.cloud.google.com/apt cloud-sdk main\n",
      "\u001b[91m  % Total    % Received % Xferd  Average Spe\u001b[0m\u001b[91med   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2537  100  2537    0     0   112k      0 --:--:-- --:--:-- --:--:--  112k:--     0\u001b[0m\u001b[91m\n",
      "\u001b[0m\u001b[91mWarning: apt-key output should not be parsed (stdout is not a terminal)\n",
      "\u001b[0mOK\n",
      "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:2 http://packages.cloud.google.com/apt cloud-sdk InRelease [6751 B]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]\n",
      "Get:4 http://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [323 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [669 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2133 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1501 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [893 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2594 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1613 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1195 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.4 kB]\n",
      "Fetched 24.5 MB in 3s (8022 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "Suggested packages:\n",
      "  google-cloud-sdk-app-engine-java google-cloud-sdk-app-engine-python\n",
      "  google-cloud-sdk-pubsub-emulator google-cloud-sdk-bigtable-emulator\n",
      "  google-cloud-sdk-datastore-emulator kubectl\n",
      "The following NEW packages will be installed:\n",
      "  google-cloud-sdk\n",
      "0 upgraded, 1 newly installed, 0 to remove and 55 not upgraded.\n",
      "Need to get 128 MB of archives.\n",
      "After this operation, 706 MB of additional disk space will be used.\n",
      "Get:1 http://packages.cloud.google.com/apt cloud-sdk/main amd64 google-cloud-sdk all 402.0.0-0 [128 MB]\n",
      "Fetched 128 MB in 1s (94.3 MB/s)\n",
      "Selecting previously unselected package google-cloud-sdk.\n",
      "(Reading database ... 41340 files and directories currently installed.)\n",
      "Preparing to unpack .../google-cloud-sdk_402.0.0-0_all.deb ...\n",
      "Unpacking google-cloud-sdk (402.0.0-0) ...\n",
      "Setting up google-cloud-sdk (402.0.0-0) ...\n",
      "Removing intermediate container 522646b711ca\n",
      " ---> bfe10bb77153\n",
      "Step 7/8 : COPY training/* ./\n",
      " ---> d0ff6ca799c6\n",
      "Step 8/8 : ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/compat/lib.real:/usr/local/hugectr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/lib:/repos/dist/lib\n",
      " ---> Running in 8844f3a09326\n",
      "Removing intermediate container 8844f3a09326\n",
      " ---> 081a29c64239\n",
      "Successfully built 081a29c64239\n",
      "Successfully tagged gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13:latest\n",
      "PUSH\n",
      "Pushing gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13\n",
      "The push refers to repository [gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13]\n",
      "b42dc4dc9f5c: Preparing\n",
      "7aaec1b1f859: Preparing\n",
      "107d54b03542: Preparing\n",
      "69c8e973fe5c: Preparing\n",
      "70c06d0ae196: Preparing\n",
      "8a8e328d9a24: Preparing\n",
      "587ae88b2a6a: Preparing\n",
      "38b81a2bf449: Preparing\n",
      "679d8cbc3f66: Preparing\n",
      "01ad26918152: Preparing\n",
      "576bd13a371e: Preparing\n",
      "ebf7770af821: Preparing\n",
      "084c6b23265c: Preparing\n",
      "9090605240e2: Preparing\n",
      "382f9420521e: Preparing\n",
      "6ea587388a52: Preparing\n",
      "2427b03a1322: Preparing\n",
      "12e703323176: Preparing\n",
      "10e4470f9175: Preparing\n",
      "2b47b98544ea: Preparing\n",
      "4eca9b30a7d0: Preparing\n",
      "28c9855b2427: Preparing\n",
      "508a2b257de0: Preparing\n",
      "f25169fb7ec5: Preparing\n",
      "7ec42d4bcc1e: Preparing\n",
      "f7dae0a4fefb: Preparing\n",
      "4f2b6384954e: Preparing\n",
      "c1c86d47e3fe: Preparing\n",
      "bb0a5e0a5b45: Preparing\n",
      "a3fe46f14851: Preparing\n",
      "5121f29a7fc1: Preparing\n",
      "70a9b882376f: Preparing\n",
      "f21fa71cb085: Preparing\n",
      "3fae03481672: Preparing\n",
      "fe552cc866fe: Preparing\n",
      "e50dd07a2d4b: Preparing\n",
      "6b814f6ef2d1: Preparing\n",
      "5e168312d805: Preparing\n",
      "2dbdd4534963: Preparing\n",
      "d6755c3d4acd: Preparing\n",
      "8a0edf8451cd: Preparing\n",
      "f1f6f96d7994: Preparing\n",
      "af6fcf83c8af: Preparing\n",
      "3990d07a9f26: Preparing\n",
      "ed753b0464e5: Preparing\n",
      "21146e80344e: Preparing\n",
      "a857ac08c88c: Preparing\n",
      "e5c3b6bc8e61: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "9dd84d4957c3: Preparing\n",
      "334cf9717da9: Preparing\n",
      "359b54514987: Preparing\n",
      "fbbd781e02a0: Preparing\n",
      "c24388e26846: Preparing\n",
      "b450269054ee: Preparing\n",
      "e7c25318945a: Preparing\n",
      "f1cc333e558f: Preparing\n",
      "88e53edab33a: Preparing\n",
      "0ddb5834cd65: Preparing\n",
      "d76b5b6c5705: Preparing\n",
      "b7a21343f225: Preparing\n",
      "af7ed92504ae: Preparing\n",
      "ed753b0464e5: Waiting\n",
      "6ea587388a52: Waiting\n",
      "21146e80344e: Waiting\n",
      "2427b03a1322: Waiting\n",
      "12e703323176: Waiting\n",
      "a857ac08c88c: Waiting\n",
      "10e4470f9175: Waiting\n",
      "2b47b98544ea: Waiting\n",
      "4eca9b30a7d0: Waiting\n",
      "28c9855b2427: Waiting\n",
      "01ad26918152: Waiting\n",
      "508a2b257de0: Waiting\n",
      "576bd13a371e: Waiting\n",
      "f25169fb7ec5: Waiting\n",
      "e5c3b6bc8e61: Waiting\n",
      "e7c25318945a: Waiting\n",
      "4f2b6384954e: Waiting\n",
      "7ec42d4bcc1e: Waiting\n",
      "f7dae0a4fefb: Waiting\n",
      "f1cc333e558f: Waiting\n",
      "c1c86d47e3fe: Waiting\n",
      "bb0a5e0a5b45: Waiting\n",
      "ebf7770af821: Waiting\n",
      "084c6b23265c: Waiting\n",
      "af7ed92504ae: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "9dd84d4957c3: Waiting\n",
      "334cf9717da9: Waiting\n",
      "9090605240e2: Waiting\n",
      "8a0edf8451cd: Waiting\n",
      "f1f6f96d7994: Waiting\n",
      "88e53edab33a: Waiting\n",
      "0ddb5834cd65: Waiting\n",
      "3990d07a9f26: Waiting\n",
      "70a9b882376f: Waiting\n",
      "af6fcf83c8af: Waiting\n",
      "38b81a2bf449: Waiting\n",
      "fbbd781e02a0: Waiting\n",
      "679d8cbc3f66: Waiting\n",
      "f21fa71cb085: Waiting\n",
      "587ae88b2a6a: Waiting\n",
      "5121f29a7fc1: Waiting\n",
      "c24388e26846: Waiting\n",
      "b450269054ee: Waiting\n",
      "5e168312d805: Waiting\n",
      "d6755c3d4acd: Waiting\n",
      "d76b5b6c5705: Waiting\n",
      "fe552cc866fe: Waiting\n",
      "3fae03481672: Waiting\n",
      "359b54514987: Waiting\n",
      "8a8e328d9a24: Waiting\n",
      "382f9420521e: Waiting\n",
      "b7a21343f225: Waiting\n",
      "2dbdd4534963: Waiting\n",
      "e50dd07a2d4b: Waiting\n",
      "b42dc4dc9f5c: Pushed\n",
      "8a8e328d9a24: Pushed\n",
      "70c06d0ae196: Pushed\n",
      "587ae88b2a6a: Layer already exists\n",
      "38b81a2bf449: Layer already exists\n",
      "679d8cbc3f66: Layer already exists\n",
      "01ad26918152: Layer already exists\n",
      "576bd13a371e: Layer already exists\n",
      "ebf7770af821: Layer already exists\n",
      "084c6b23265c: Layer already exists\n",
      "9090605240e2: Layer already exists\n",
      "382f9420521e: Layer already exists\n",
      "6ea587388a52: Layer already exists\n",
      "2427b03a1322: Layer already exists\n",
      "12e703323176: Layer already exists\n",
      "10e4470f9175: Layer already exists\n",
      "2b47b98544ea: Layer already exists\n",
      "4eca9b30a7d0: Layer already exists\n",
      "28c9855b2427: Layer already exists\n",
      "508a2b257de0: Layer already exists\n",
      "f25169fb7ec5: Layer already exists\n",
      "7ec42d4bcc1e: Layer already exists\n",
      "f7dae0a4fefb: Layer already exists\n",
      "c1c86d47e3fe: Layer already exists\n",
      "4f2b6384954e: Layer already exists\n",
      "bb0a5e0a5b45: Layer already exists\n",
      "a3fe46f14851: Layer already exists\n",
      "5121f29a7fc1: Layer already exists\n",
      "70a9b882376f: Layer already exists\n",
      "f21fa71cb085: Layer already exists\n",
      "3fae03481672: Layer already exists\n",
      "fe552cc866fe: Layer already exists\n",
      "e50dd07a2d4b: Layer already exists\n",
      "6b814f6ef2d1: Layer already exists\n",
      "5e168312d805: Layer already exists\n",
      "2dbdd4534963: Layer already exists\n",
      "d6755c3d4acd: Layer already exists\n",
      "8a0edf8451cd: Layer already exists\n",
      "f1f6f96d7994: Layer already exists\n",
      "af6fcf83c8af: Layer already exists\n",
      "3990d07a9f26: Layer already exists\n",
      "ed753b0464e5: Layer already exists\n",
      "21146e80344e: Layer already exists\n",
      "e5c3b6bc8e61: Layer already exists\n",
      "a857ac08c88c: Layer already exists\n",
      "9dd84d4957c3: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "359b54514987: Layer already exists\n",
      "334cf9717da9: Layer already exists\n",
      "c24388e26846: Layer already exists\n",
      "fbbd781e02a0: Layer already exists\n",
      "e7c25318945a: Layer already exists\n",
      "b450269054ee: Layer already exists\n",
      "88e53edab33a: Layer already exists\n",
      "f1cc333e558f: Layer already exists\n",
      "0ddb5834cd65: Layer already exists\n",
      "d76b5b6c5705: Layer already exists\n",
      "b7a21343f225: Layer already exists\n",
      "69c8e973fe5c: Pushed\n",
      "af7ed92504ae: Layer already exists\n",
      "107d54b03542: Pushed\n",
      "7aaec1b1f859: Pushed\n",
      "latest: digest: sha256:dc4e0fba0c5bc1a51925de65a05afa8c0d85b70197450a1e25056a017267cd85 size: 13371\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                       IMAGES                                                          STATUS\n",
      "fab486f3-ccbc-4666-8ef0-fcc0454f1dde  2022-09-13T21:53:51+00:00  5M23S     gs://hybrid-vertex_cloudbuild/source/1663106031.143978-8a29bbba89d949f1a8d2ec5cb8c03e4e.tgz  gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13 (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "FILE_LOCATION = './src'\n",
    "! gcloud builds submit --config src/cloudbuild.yaml --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION --timeout=2h --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c19ca-3f74-4be3-9409-3ea2cf239ad3",
   "metadata": {},
   "source": [
    "## Vertex Training\n",
    "\n",
    "* See [here](https://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus) for GPU config options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f5765-4c6f-4b45-a79f-f7f287ee4137",
   "metadata": {},
   "source": [
    "## Prepare Worker Pool Specs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feb95bf-dd00-49ba-ab8f-a19e3c8f1e55",
   "metadata": {},
   "source": [
    "#### Artifact Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "340fd1c1-f311-493d-accc-4580cbd03903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DATA: /gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/train\n",
      "VALID_DATA: /gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/valid\n",
      "WORKFLOW_DIR: gs://spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-analyzed\n",
      "SCHEMA_PATH: /gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-defined/train/schema.pbtxt\n",
      "MODEL_DIR: gs://spotify-merlin-v1/model-dir/v13\n"
     ]
    }
   ],
   "source": [
    "# full dataset - output of preprocessing pipeline\n",
    "TRAIN_DATA = f'/gcs/{BUCKET}/nvt-preprocessing-spotify-v32-subset/nvt-processed/train'\n",
    "VALID_DATA = f'/gcs/{BUCKET}/nvt-preprocessing-spotify-v32-subset/nvt-processed/valid'\n",
    "WORKFLOW_DIR = f'gs://{BUCKET}/nvt-preprocessing-spotify-v32-subset/nvt-analyzed'\n",
    "SCHEMA_PATH = f'/gcs/{BUCKET}/nvt-preprocessing-spotify-v32-subset/nvt-defined/train/schema.pbtxt' # Schema used by the training pipepine\n",
    "\n",
    "# smaller dataset for testing\n",
    "# TRAIN_DATA = '/gcs/spotify-builtin-2t/merlin-processed/train/'\n",
    "# VALID_DATA = '/gcs/spotify-builtin-2t/merlin-processed/valid/'\n",
    "# WORKFLOW_DIR = 'gs://spotify-builtin-2t/merlin-processed/workflow/2t-spotify-workflow'\n",
    "\n",
    "# location to save trained model artifacts\n",
    "MODEL_DIR = f'gs://{BUCKET}/model-dir/{VERSION}'\n",
    "\n",
    "print(f'TRAIN_DATA: {TRAIN_DATA}')\n",
    "print(f'VALID_DATA: {VALID_DATA}')\n",
    "print(f'WORKFLOW_DIR: {WORKFLOW_DIR}')\n",
    "print(f'SCHEMA_PATH: {SCHEMA_PATH}')\n",
    "print(f'MODEL_DIR: {MODEL_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1cae3-b90d-4118-a45b-dc8aeafa3f2e",
   "metadata": {},
   "source": [
    "#### Configure worker pools\n",
    "\n",
    "**Reduction Server**\n",
    "\n",
    "* Consider the network bandwidth supported by a reducer replica’s machine type\n",
    "> * In GCP, a VM’s machine type defines its maximum possible egress bandwidth. \n",
    "> * For example, the egress bandwidth of the `n1-highcpu-16` machine type is limited at 32 Gbps\n",
    "> See [Network bandwidths and GPUs](https://cloud.google.com/compute/docs/gpus/gpu-network-bandwidth) for details\n",
    "* Reductions servers **do not** use GPUs\n",
    "* For the maximum available bandwidth of each node in the third worker pool, see the \"Maximum egress bandwidth (Gbps)\" columns in [General-purpose machine family](https://cloud.google.com/compute/docs/general-purpose-machines)\n",
    "\n",
    "Because reducers perform a very limited function, aggregating blocks of gradients, they can run on relatively low-powered and cost effective machines. \n",
    "Even with a large number of gradients this computation does not require accelerated hardware or high CPU or memory resources. \n",
    "\n",
    "**To avoid network bottlenecks, the total aggregate bandwidth of all replicas in the reducer worker pool must be greater or equal to the total aggregate bandwidth of all replicas in worker pools 0 and 1, which host the GPU workers.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf963e0b-52c5-4757-9042-49f963779ddd",
   "metadata": {},
   "source": [
    "#### Hardware Accelerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "6fe566de-99dc-4fb8-8da0-477ba7181e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORKER_MACHINE_TYPE: a2-highgpu-1g\n",
      "REPLICA_COUNT: 1\n",
      "ACCELERATOR_TYPE: NVIDIA_TESLA_A100\n",
      "PER_MACHINE_ACCELERATOR_COUNT: 1\n",
      "REDUCTION_SERVER_COUNT: 0\n",
      "REDUCTION_SERVER_MACHINE_TYPE: n1-highcpu-16\n",
      "gpus: [[0]]\n"
     ]
    }
   ],
   "source": [
    "# WORKER_MACHINE_TYPE = 'a2-highgpu-4g'\n",
    "WORKER_MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "REPLICA_COUNT = 1\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "# PER_MACHINE_ACCELERATOR_COUNT = 4\n",
    "PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "\n",
    "DISTRIBUTE_STRATEGY = 'single' # single mirrored multiworker tpu\n",
    "\n",
    "\n",
    "# if single-node training, RS server = 0\n",
    "REDUCTION_SERVER_COUNT = 0                                                      \n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "\n",
    "gpus = json.dumps([list(range(PER_MACHINE_ACCELERATOR_COUNT))]).replace(' ','')\n",
    "\n",
    "\n",
    "print(f'WORKER_MACHINE_TYPE: {WORKER_MACHINE_TYPE}')\n",
    "print(f'REPLICA_COUNT: {REPLICA_COUNT}')\n",
    "print(f'ACCELERATOR_TYPE: {ACCELERATOR_TYPE}')\n",
    "print(f'PER_MACHINE_ACCELERATOR_COUNT: {PER_MACHINE_ACCELERATOR_COUNT}')\n",
    "print(f'REDUCTION_SERVER_COUNT: {REDUCTION_SERVER_COUNT}')\n",
    "print(f'REDUCTION_SERVER_MACHINE_TYPE: {REDUCTION_SERVER_MACHINE_TYPE}')\n",
    "print(f'gpus: {gpus}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88c0d8b-3612-440b-9dd9-a7e72d867f60",
   "metadata": {},
   "source": [
    "#### Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "f98eaeae-014e-490a-885a-b9110b42ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: nb-vtt-v13-single\n",
      "RUN_NAME: run-20220913-223315\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_NAME = f\"nb-vtt-{VERSION}-{DISTRIBUTE_STRATEGY}\"\n",
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "\n",
    "print(f'EXPERIMENT_NAME: {EXPERIMENT_NAME}')\n",
    "print(f'RUN_NAME: {RUN_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4a17bb69-325f-48fa-ac40-db0e67027d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sh',\n",
      " '-euc',\n",
      " 'python -m train_task --per_gpu_batch_size=2048     --model_name=twotower '\n",
      " '--train_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/train     '\n",
      " '--valid_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/valid     '\n",
      " '--schema=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-defined/train/schema.pbtxt     '\n",
      " '--workflow_dir=gs://spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-analyzed     '\n",
      " '--max_iter=25000 --num_epochs=5 --gpus=[[0]]     '\n",
      " '--model_dir=gs://spotify-merlin-v1/model-dir/v13 --distribute=single     '\n",
      " '--experiment_name=nb-vtt-v13-single --experiment_run=run-20220913-223315']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NUM_EPOCHS = 5\n",
    "MAX_ITERATIONS = 25000\n",
    "# EVAL_INTERVAL = 1000\n",
    "# EVAL_BATCHES = 500\n",
    "# EVAL_BATCHES_FINAL = 2500\n",
    "# DISPLAY_INTERVAL = 200\n",
    "# SNAPSHOT_INTERVAL = 0\n",
    "PER_GPU_BATCH_SIZE = 2048\n",
    "# LR = 0.001\n",
    "# DROPOUT_RATE = 0.5\n",
    "# NUM_WORKERS = 12\n",
    "# LAYER_SIZES='[1024,512,256]'\n",
    "\n",
    "\n",
    "WORKER_CMD = [\n",
    "    'sh',\n",
    "    '-euc',\n",
    "    f'''python -m train_task --per_gpu_batch_size={PER_GPU_BATCH_SIZE} \\\n",
    "    --model_name={MODEL_NAME} --train_dir={TRAIN_DATA} \\\n",
    "    --valid_dir={VALID_DATA} \\\n",
    "    --schema={SCHEMA_PATH} \\\n",
    "    --workflow_dir={WORKFLOW_DIR} \\\n",
    "    --max_iter={MAX_ITERATIONS} --num_epochs={NUM_EPOCHS} --gpus={gpus} \\\n",
    "    --model_dir={MODEL_DIR} --distribute={DISTRIBUTE_STRATEGY} \\\n",
    "    --experiment_name={EXPERIMENT_NAME} --experiment_run={RUN_NAME}'''\n",
    "]    \n",
    "\n",
    "pprint(WORKER_CMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3518dc-2696-44d7-abd7-e76a4340730f",
   "metadata": {},
   "source": [
    "### Create a custom training job\n",
    "\n",
    "* specifies multiple machines (nodes) in a training cluster. \n",
    "\n",
    "The training service allocates the resources for the machine types you specify. \n",
    "* A running job on a given node is called a `replica`\n",
    "* A group of `replicas` with the same configuration is called a `worker_pool` \n",
    "* Vertex Training provides 4 `worker pools` to cover the different types of machine tasks\n",
    "\n",
    "To use the Reduction Server, you'll need to use 3 of the 4 available worker pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e4729234-fad5-4911-b17b-59dfae3589dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_worker_pool_specs(\n",
    "    image_uri,\n",
    "    # args,\n",
    "    cmd,\n",
    "    replica_count=1,\n",
    "    machine_type=\"n1-standard-16\",\n",
    "    accelerator_count=1,\n",
    "    accelerator_type=\"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "    reduction_server_count=0,\n",
    "    reduction_server_machine_type=\"n1-highcpu-16\",\n",
    "    reduction_server_image_uri=\"us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest\",\n",
    "):\n",
    "\n",
    "    if accelerator_count > 0:\n",
    "        machine_spec = {\n",
    "            \"machine_type\": machine_type,\n",
    "            \"accelerator_type\": accelerator_type,\n",
    "            \"accelerator_count\": accelerator_count,\n",
    "        }\n",
    "    else:\n",
    "        machine_spec = {\"machine_type\": machine_type}\n",
    "\n",
    "    container_spec = {\n",
    "        \"image_uri\": image_uri,\n",
    "        # \"args\": args,\n",
    "        \"command\": cmd,\n",
    "    }\n",
    "\n",
    "    chief_spec = {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": machine_spec,\n",
    "        \"container_spec\": container_spec,\n",
    "    }\n",
    "\n",
    "    worker_pool_specs = [chief_spec]\n",
    "    if replica_count > 1:\n",
    "        workers_spec = {\n",
    "            \"replica_count\": replica_count - 1,\n",
    "            \"machine_spec\": machine_spec,\n",
    "            \"container_spec\": container_spec,\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "    if reduction_server_count > 1:\n",
    "        workers_spec = {\n",
    "            \"replica_count\": reduction_server_count,\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": reduction_server_machine_type,\n",
    "            },\n",
    "            \"container_spec\": {\"image_uri\": reduction_server_image_uri},\n",
    "        }\n",
    "        worker_pool_specs.append(workers_spec)\n",
    "\n",
    "    return worker_pool_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "6b7f68a1-c547-4232-9d2c-d68b52a3e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'command': ['sh',\n",
      "                                 '-euc',\n",
      "                                 'python -m train_task '\n",
      "                                 '--per_gpu_batch_size=2048     '\n",
      "                                 '--model_name=twotower '\n",
      "                                 '--train_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/train     '\n",
      "                                 '--valid_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/valid     '\n",
      "                                 '--schema=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-defined/train/schema.pbtxt     '\n",
      "                                 '--workflow_dir=gs://spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-analyzed     '\n",
      "                                 '--max_iter=25000 --num_epochs=5 '\n",
      "                                 '--gpus=[[0]]     '\n",
      "                                 '--model_dir=gs://spotify-merlin-v1/model-dir/v13 '\n",
      "                                 '--distribute=single     '\n",
      "                                 '--experiment_name=nb-vtt-v13-single '\n",
      "                                 '--experiment_run=run-20220913-223315'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_A100',\n",
      "                   'machine_type': 'a2-highgpu-1g'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "WORKER_POOL_SPECS = prepare_worker_pool_specs(\n",
    "    image_uri=IMAGE_URI,\n",
    "    # args=WORKER_ARGS,\n",
    "    cmd=WORKER_CMD,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=WORKER_MACHINE_TYPE,\n",
    "    accelerator_count=PER_MACHINE_ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ae71f-4ca7-4ff7-9171-aa51db0aac54",
   "metadata": {},
   "source": [
    "### Submit and monitor train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8edac21e-01e4-466b-8d27-081d9d5a6a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/934903580331/locations/us-central1/customJobs/2727438923134402560\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/934903580331/locations/us-central1/customJobs/2727438923134402560')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/2727438923134402560?project=934903580331\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 access the interactive shell terminals for the custom job:\n",
      "workerpool0-0:\n",
      "cc81a5ee2aaddd77-dot-us-central1.aiplatform-training.googleusercontent.com\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/934903580331/locations/us-central1/customJobs/2727438923134402560 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "job_name = f'merlin_towers_{VERSION}_{time.strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "base_output_dir =  os.path.join(WORKSPACE, job_name)\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=WORKER_POOL_SPECS,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "job.run(\n",
    "    sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False,\n",
    "    enable_web_access=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec67001-6db7-473c-9c75-cabe40fdf7f2",
   "metadata": {},
   "source": [
    "### Submit and monitor train job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ddbd3-ffc6-4d04-8e46-6f920f1b3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # full dataset - output of preprocessing pipeline\n",
    "# TRAIN_DATA = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/train'\n",
    "# VALID_DATA = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/valid'\n",
    "# WORKFLOW_DIR = f'gs://{BUCKET}/nvt-preprocessing-spotify-v32-subset/nvt-analyzed'\n",
    "# SCHEMA_PATH = '/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-defined/train/schema.pbtxt' # Schema used by the training pipepine\n",
    "\n",
    "# # smaller dataset for testing\n",
    "# # TRAIN_DATA = '/gcs/spotify-builtin-2t/merlin-processed/train/'\n",
    "# # VALID_DATA = '/gcs/spotify-builtin-2t/merlin-processed/valid/'\n",
    "# # WORKFLOW_DIR = 'gs://spotify-builtin-2t/merlin-processed/workflow/2t-spotify-workflow'\n",
    "\n",
    "# # location to save trained model artifacts\n",
    "# MODEL_DIR = f'gs://{BUCKET}/model-dir/{VERSION}'\n",
    "\n",
    "# # # Single A100 GPU config\n",
    "# # MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "# # ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "# # ACCELERATOR_NUM = 1\n",
    "\n",
    "# # Multi A100 GPU config\n",
    "# MACHINE_TYPE = 'a2-highgpu-2g'\n",
    "# ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "# ACCELERATOR_NUM = 2\n",
    "\n",
    "# # # Smaller GPU config\n",
    "# # MACHINE_TYPE = \"n1-standard-16\"\n",
    "# # ACCELERATOR_TYPE = \"NVIDIA_TESLA_T4\"\n",
    "# # ACCELERATOR_NUM = 1\n",
    "\n",
    "# gpus = json.dumps([list(range(ACCELERATOR_NUM))]).replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d9272963-eb03-45a1-b003-a27f2b317888",
   "metadata": {},
   "outputs": [],
   "source": [
    "                 \n",
    "# worker_pool_specs =  [\n",
    "#     {\n",
    "#         \"machine_spec\": {\n",
    "#             \"machine_type\": MACHINE_TYPE,\n",
    "#             \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "#             \"accelerator_count\": ACCELERATOR_NUM,\n",
    "#         },\n",
    "#         \"replica_count\": 1,\n",
    "#         \"container_spec\": {\n",
    "#             \"image_uri\": IMAGE_URI,\n",
    "#             \"command\": [\"python\", \"-m\", \"train_task\"],\n",
    "#             \"args\": [\n",
    "#                 f'--per_gpu_batch_size={PER_GPU_BATCH_SIZE}',\n",
    "#                 f'--model_name={MODEL_NAME}',\n",
    "#                 f'--train_dir={TRAIN_DATA}',\n",
    "#                 f'--valid_dir={VALID_DATA}',\n",
    "#                 f'--schema={SCHEMA_PATH}',\n",
    "#                 f'--workflow_dir={WORKFLOW_DIR}',\n",
    "#                 # f'--layer_sizes={LAYER_SIZES}',\n",
    "#                 # f'--slot_size_array={cardinalities}',\n",
    "#                 f'--max_iter={MAX_ITERATIONS}',\n",
    "#                 # f'--max_eval_batches={EVAL_BATCHES}',\n",
    "#                 # f'--eval_batches={EVAL_BATCHES_FINAL}',\n",
    "#                 # f'--dropout_rate={DROPOUT_RATE}',\n",
    "#                 # f'--lr={LR}',\n",
    "#                 # f'--num_workers={NUM_WORKERS}',\n",
    "#                 f'--num_epochs={NUM_EPOCHS}',\n",
    "#                 # f'--eval_interval={EVAL_INTERVAL}',\n",
    "#                 # f'--snapshot={SNAPSHOT_INTERVAL}',\n",
    "#                 # f'--display_interval={DISPLAY_INTERVAL}',\n",
    "#                 f'--gpus={gpus}',\n",
    "#                 # f'--train_dir, --valid_dir, --layer_sizes\n",
    "#             ],\n",
    "#         },\n",
    "#     }\n",
    "# ]\n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": MACHINE_TYPE,\n",
    "            \"accelerator_type\": ACCELERATOR_TYPE,\n",
    "            \"accelerator_count\": ACCELERATOR_NUM,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            'command': ['sh','-euc',f'''\n",
    "                    python -m train_task --per_gpu_batch_size={PER_GPU_BATCH_SIZE} \\\n",
    "                    --model_name={MODEL_NAME} --train_dir={TRAIN_DATA} \\\n",
    "                    --valid_dir={VALID_DATA} \\\n",
    "                    --schema={SCHEMA_PATH} \\\n",
    "                    --workflow_dir={WORKFLOW_DIR} \\\n",
    "                    --max_iter={MAX_ITERATIONS} --num_epochs={NUM_EPOCHS} --gpus={gpus} \\\n",
    "                    --model_dir={MODEL_DIR}\n",
    "                    '''\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e60c9b20-c8c7-438e-b0c4-e1a69b692a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'command': ['sh',\n",
      "                                 '-euc',\n",
      "                                 '\\n'\n",
      "                                 '                    python -m train_task '\n",
      "                                 '--per_gpu_batch_size=2048                     '\n",
      "                                 '--model_name=twotower '\n",
      "                                 '--train_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/train                     '\n",
      "                                 '--valid_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-processed/valid                     '\n",
      "                                 '--schema=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-defined/train/schema.pbtxt                     '\n",
      "                                 '--workflow_dir=gs://spotify-merlin-v1/nvt-preprocessing-spotify-v32-subset/nvt-analyzed                     '\n",
      "                                 '--max_iter=25000 --num_epochs=10 '\n",
      "                                 '--gpus=[[0,1]]                     '\n",
      "                                 '--model_dir=gs://spotify-merlin-v1/model-dir/v13\\n'\n",
      "                                 '                    '],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/merlin-tf-twotower-training-v13'},\n",
      "  'machine_spec': {'accelerator_count': 2,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_A100',\n",
      "                   'machine_type': 'a2-highgpu-1g'},\n",
      "  'replica_count': 2}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(worker_pool_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f05c5b66-4771-45ad-bc51-7bb430af60dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n"
     ]
    }
   ],
   "source": [
    "job_name = 'merlin_towers_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir =  os.path.join(WORKSPACE, job_name)\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    base_output_dir=base_output_dir\n",
    ")\n",
    "job.run(\n",
    "    sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    "    restart_job_on_worker_restart=False,\n",
    "    enable_web_access=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b634a0-3866-4aaa-bbf9-7d87b63d7519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "408ce817-2679-4dc8-8658-12aa33e14676",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca78d1a-ba3d-42dc-82ee-d6c8b3910790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker_pool_specs =  [\n",
    "#     {\n",
    "#         \"machine_spec\": {\n",
    "#             \"machine_type\": \"a2-highgpu-1g\",\n",
    "#             \"accelerator_type\": \"NVIDIA_TESLA_A100\",\n",
    "#             \"accelerator_count\": 1,\n",
    "#         },\n",
    "#         \"replica_count\": 1,\n",
    "#         \"container_spec\": {\n",
    "#             \"image_uri\": IMAGE_URI,\n",
    "#             'command': ['sh','-euc','''\n",
    "#                     python -m train_task --per_gpu_batch_size=2048 \\\n",
    "#                     --model_name=twotower --train_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-processed/train \\\n",
    "#                     --valid_dir=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-processed/valid \\\n",
    "#                     --schema=/gcs/spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-defined/train/schema.pbtxt \\\n",
    "#                     --workflow_dir=gs://spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-analyzed \\\n",
    "#                     --max_iter=25000 --num_epochs=2 --gpus=[[0]] --model_dir={MODEL_DIR}\n",
    "#                     '''\n",
    "#             ]\n",
    "#         }\n",
    "#     }\n",
    "# ]\n",
    "# spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-processed\n",
    "# spotify-merlin-v1/nvt-preprocessing-spotify-v24/nvt-processed/train"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
